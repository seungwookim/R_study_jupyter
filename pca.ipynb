{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA 주성분 분석 \n",
    "주성분 분석은 하나의 관측 대상에 대해 많은 관측 값(다변량(多變量))이 있는 경우 하나 하나의 변수별 또는 2개 변수의 상관관계별로 검토해도 전체 상을 파악할 수 없는 경우가 있다. 주성분 분석은 많은 변수의 분산방식(분산ㆍ공분산)의 패턴을 간결하게 ‘표현’하는 주성분을 원래 변수의 선형결합(무게에 대한 평균점)으로서 추출하는 통계기법이다. 즉, p개의 변수가 있는 경우 거기에서 얻은 정보를 p보다 상당히 작은 k개의 변수로 요약하는 것이다. 다른 설명으로는 p차원 공간의 축을 회전시켜 많은 변수의 분산을 가장 잘 ‘반영’한 소수의 새로운 축을 찾아내는 기술이라고도 할 수 있다.(네이버 펌) <br>\n",
    "결론적으로 활용관점에서 이야기하면 PCA 는 PCA 자체를 사용해서 Anomaly Detection 등을 수행하거나, 회귀분석등을 수행하기 전에 전처리 용도로 사용할 수 있다. <참조 : http://rfriend.tistory.com/61>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 생성 \n",
    "PCA 분석을 위한 가상의 데이터를 만들어 보자. 데이터의 형태는 아래와 같다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x</th><th scope=col>y</th><th scope=col>z</th><th scope=col>r</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1       </td><td> 1.037207</td><td>-3.388737</td><td>2.3267907</td></tr>\n",
       "\t<tr><td> 2       </td><td> 2.036531</td><td> 3.390203</td><td>1.1633954</td></tr>\n",
       "\t<tr><td> 3       </td><td> 3.238043</td><td>-1.306867</td><td>0.7755969</td></tr>\n",
       "\t<tr><td> 4       </td><td> 3.812732</td><td> 1.346827</td><td>0.5816977</td></tr>\n",
       "\t<tr><td> 5       </td><td> 5.159830</td><td> 2.564558</td><td>0.4653581</td></tr>\n",
       "\t<tr><td> 6       </td><td> 5.976359</td><td> 9.474380</td><td>0.3877985</td></tr>\n",
       "\t<tr><td> 7       </td><td> 6.611648</td><td> 7.098981</td><td>0.3323987</td></tr>\n",
       "\t<tr><td> 8       </td><td> 8.395447</td><td> 7.687069</td><td>0.2908488</td></tr>\n",
       "\t<tr><td> 9       </td><td> 9.390938</td><td>13.205831</td><td>0.2585323</td></tr>\n",
       "\t<tr><td>10       </td><td>10.126063</td><td>18.925502</td><td>0.2326791</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " x & y & z & r\\\\\n",
       "\\hline\n",
       "\t  1        &  1.037207 & -3.388737 & 2.3267907\\\\\n",
       "\t  2        &  2.036531 &  3.390203 & 1.1633954\\\\\n",
       "\t  3        &  3.238043 & -1.306867 & 0.7755969\\\\\n",
       "\t  4        &  3.812732 &  1.346827 & 0.5816977\\\\\n",
       "\t  5        &  5.159830 &  2.564558 & 0.4653581\\\\\n",
       "\t  6        &  5.976359 &  9.474380 & 0.3877985\\\\\n",
       "\t  7        &  6.611648 &  7.098981 & 0.3323987\\\\\n",
       "\t  8        &  8.395447 &  7.687069 & 0.2908488\\\\\n",
       "\t  9        &  9.390938 & 13.205831 & 0.2585323\\\\\n",
       "\t 10        & 10.126063 & 18.925502 & 0.2326791\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "x | y | z | r | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "|  1        |  1.037207 | -3.388737 | 2.3267907 | \n",
       "|  2        |  2.036531 |  3.390203 | 1.1633954 | \n",
       "|  3        |  3.238043 | -1.306867 | 0.7755969 | \n",
       "|  4        |  3.812732 |  1.346827 | 0.5816977 | \n",
       "|  5        |  5.159830 |  2.564558 | 0.4653581 | \n",
       "|  6        |  5.976359 |  9.474380 | 0.3877985 | \n",
       "|  7        |  6.611648 |  7.098981 | 0.3323987 | \n",
       "|  8        |  8.395447 |  7.687069 | 0.2908488 | \n",
       "|  9        |  9.390938 | 13.205831 | 0.2585323 | \n",
       "| 10        | 10.126063 | 18.925502 | 0.2326791 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   x  y         z         r        \n",
       "1   1  1.037207 -3.388737 2.3267907\n",
       "2   2  2.036531  3.390203 1.1633954\n",
       "3   3  3.238043 -1.306867 0.7755969\n",
       "4   4  3.812732  1.346827 0.5816977\n",
       "5   5  5.159830  2.564558 0.4653581\n",
       "6   6  5.976359  9.474380 0.3877985\n",
       "7   7  6.611648  7.098981 0.3323987\n",
       "8   8  8.395447  7.687069 0.2908488\n",
       "9   9  9.390938 13.205831 0.2585323\n",
       "10 10 10.126063 18.925502 0.2326791"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x<-1:10\n",
    "y<-x+runif(10,min=-.5,max=.5)\n",
    "z<-x+y+runif(10,min=-10,max=.10)\n",
    "r<-runif(1, -5.0, 17.5)/x\n",
    "(data<-data.frame(x,y,z,r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Princomp 함수 \n",
    "별도의 회전없이 한번 pca 분석을 생성한 데이터에 실행하여 보자. 실제로는 varimax 회전등을 사용하여 PCA 분석을 실행해야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Importance of components:\n",
       "                         Comp.1     Comp.2      Comp.3       Comp.4\n",
       "Standard deviation     7.524792 1.47233245 0.355270937 0.1477322279\n",
       "Proportion of Variance 0.960708 0.03678021 0.002141518 0.0003702993\n",
       "Cumulative Proportion  0.960708 0.99748818 0.999629701 1.0000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Comp.1</th><th scope=col>Comp.2</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 11.337470</td><td>-0.7559784</td></tr>\n",
       "\t<tr><td>  4.757634</td><td>-2.9356396</td></tr>\n",
       "\t<tr><td>  7.925079</td><td> 0.8880388</td></tr>\n",
       "\t<tr><td>  5.074977</td><td> 0.4556479</td></tr>\n",
       "\t<tr><td>  3.165964</td><td> 1.2342254</td></tr>\n",
       "\t<tr><td> -3.392634</td><td>-1.2933249</td></tr>\n",
       "\t<tr><td> -1.972852</td><td> 0.9190895</td></tr>\n",
       "\t<tr><td> -3.503169</td><td> 2.2822800</td></tr>\n",
       "\t<tr><td> -8.940516</td><td> 0.5843858</td></tr>\n",
       "\t<tr><td>-14.451952</td><td>-1.3787245</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " Comp.1 & Comp.2\\\\\n",
       "\\hline\n",
       "\t  11.337470 & -0.7559784\\\\\n",
       "\t   4.757634 & -2.9356396\\\\\n",
       "\t   7.925079 &  0.8880388\\\\\n",
       "\t   5.074977 &  0.4556479\\\\\n",
       "\t   3.165964 &  1.2342254\\\\\n",
       "\t  -3.392634 & -1.2933249\\\\\n",
       "\t  -1.972852 &  0.9190895\\\\\n",
       "\t  -3.503169 &  2.2822800\\\\\n",
       "\t  -8.940516 &  0.5843858\\\\\n",
       "\t -14.451952 & -1.3787245\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Comp.1 | Comp.2 | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "|  11.337470 | -0.7559784 | \n",
       "|   4.757634 | -2.9356396 | \n",
       "|   7.925079 |  0.8880388 | \n",
       "|   5.074977 |  0.4556479 | \n",
       "|   3.165964 |  1.2342254 | \n",
       "|  -3.392634 | -1.2933249 | \n",
       "|  -1.972852 |  0.9190895 | \n",
       "|  -3.503169 |  2.2822800 | \n",
       "|  -8.940516 |  0.5843858 | \n",
       "| -14.451952 | -1.3787245 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      Comp.1     Comp.2    \n",
       " [1,]  11.337470 -0.7559784\n",
       " [2,]   4.757634 -2.9356396\n",
       " [3,]   7.925079  0.8880388\n",
       " [4,]   5.074977  0.4556479\n",
       " [5,]   3.165964  1.2342254\n",
       " [6,]  -3.392634 -1.2933249\n",
       " [7,]  -1.972852  0.9190895\n",
       " [8,]  -3.503169  2.2822800\n",
       " [9,]  -8.940516  0.5843858\n",
       "[10,] -14.451952 -1.3787245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr<-princomp(data)\n",
    "summary(pr)\n",
    "pr$scores[,1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회전 후 PCA 분석 \n",
    "회전후 PCA 분석을 하기 위해서 별도의 라이브러리를 사용한다. 아래의 내용은 설명력이 높은 변수부터 설명력이 어떻게 변하는지를 보여주는데, 몇개의 주성분을 사용하여 차원을 구성하는 것이 적합한지를 plot 을 사용해서 판단해보도록 한다. <br>\n",
    "Summary 결과를 보면 첫번째 항목인 x 하나만 주성분으로 사용하여도 충분하다고 판단된다. 이 부분은 당연히 다른 모든 변수를 x 를 기준으로 만들었기 때문이라고 볼 수 있겠다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#install.packages(c(\"psych\",\"GPArotation\"))\n",
    "library(psych)\n",
    "library(GPArotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 몇개의 주성분이 의미가 있는가?\n",
    "급격하게 score 가 떨어지는 부분전까지의 주성분을 사용하면 되겠다... 아래의 예라고 하면 2개 쓰면 되겠다 싶다.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): could not find function \"principal\"\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): could not find function \"principal\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "prv<-principal(data, nfactors=3, rotate=\"varimax\")\n",
    "# 주성분 2개만 사용하면 될 듯 \n",
    "plot(prv$values, type='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# varimax Rotation PCA 분석\n",
    "차원 3개로 PCA 분석 내용을 식으로 만들어보면 아래와 같이 될 것이다. 주성분 RC3 이라는 녀석은 x와는 0.57 정도의 상관관계 r 과는 -0.305의 상관 관계가 있다. 라고 해석하면 되겠다. <br>\n",
    "그러니까 우리가 PCA 분석한 모델을 가지고 새로운 데이터에 대해서 차원의 score 를 구하고자 한다면 아래와 같은 식을 실행하면 되는 것인데, 실제로는 model.values 를 통해서 유의미한 주성분의 갯수를 구하고 해당 갯수만큼만 활용한 식으로 차원 score 를 구해주면 되겠다. <br>\n",
    "(참고: RC3 = 0.570*x + 0.561*y + 0.853*z -0.305*r) <Br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'values'</li>\n",
       "\t<li>'rotation'</li>\n",
       "\t<li>'n.obs'</li>\n",
       "\t<li>'communality'</li>\n",
       "\t<li>'loadings'</li>\n",
       "\t<li>'fit'</li>\n",
       "\t<li>'fit.off'</li>\n",
       "\t<li>'fn'</li>\n",
       "\t<li>'Call'</li>\n",
       "\t<li>'uniquenesses'</li>\n",
       "\t<li>'complexity'</li>\n",
       "\t<li>'chi'</li>\n",
       "\t<li>'EPVAL'</li>\n",
       "\t<li>'R2'</li>\n",
       "\t<li>'objective'</li>\n",
       "\t<li>'residual'</li>\n",
       "\t<li>'rms'</li>\n",
       "\t<li>'factors'</li>\n",
       "\t<li>'dof'</li>\n",
       "\t<li>'null.dof'</li>\n",
       "\t<li>'null.model'</li>\n",
       "\t<li>'criteria'</li>\n",
       "\t<li>'STATISTIC'</li>\n",
       "\t<li>'PVAL'</li>\n",
       "\t<li>'weights'</li>\n",
       "\t<li>'r.scores'</li>\n",
       "\t<li>'rot.mat'</li>\n",
       "\t<li>'Vaccounted'</li>\n",
       "\t<li>'Structure'</li>\n",
       "\t<li>'scores'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'values'\n",
       "\\item 'rotation'\n",
       "\\item 'n.obs'\n",
       "\\item 'communality'\n",
       "\\item 'loadings'\n",
       "\\item 'fit'\n",
       "\\item 'fit.off'\n",
       "\\item 'fn'\n",
       "\\item 'Call'\n",
       "\\item 'uniquenesses'\n",
       "\\item 'complexity'\n",
       "\\item 'chi'\n",
       "\\item 'EPVAL'\n",
       "\\item 'R2'\n",
       "\\item 'objective'\n",
       "\\item 'residual'\n",
       "\\item 'rms'\n",
       "\\item 'factors'\n",
       "\\item 'dof'\n",
       "\\item 'null.dof'\n",
       "\\item 'null.model'\n",
       "\\item 'criteria'\n",
       "\\item 'STATISTIC'\n",
       "\\item 'PVAL'\n",
       "\\item 'weights'\n",
       "\\item 'r.scores'\n",
       "\\item 'rot.mat'\n",
       "\\item 'Vaccounted'\n",
       "\\item 'Structure'\n",
       "\\item 'scores'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'values'\n",
       "2. 'rotation'\n",
       "3. 'n.obs'\n",
       "4. 'communality'\n",
       "5. 'loadings'\n",
       "6. 'fit'\n",
       "7. 'fit.off'\n",
       "8. 'fn'\n",
       "9. 'Call'\n",
       "10. 'uniquenesses'\n",
       "11. 'complexity'\n",
       "12. 'chi'\n",
       "13. 'EPVAL'\n",
       "14. 'R2'\n",
       "15. 'objective'\n",
       "16. 'residual'\n",
       "17. 'rms'\n",
       "18. 'factors'\n",
       "19. 'dof'\n",
       "20. 'null.dof'\n",
       "21. 'null.model'\n",
       "22. 'criteria'\n",
       "23. 'STATISTIC'\n",
       "24. 'PVAL'\n",
       "25. 'weights'\n",
       "26. 'r.scores'\n",
       "27. 'rot.mat'\n",
       "28. 'Vaccounted'\n",
       "29. 'Structure'\n",
       "30. 'scores'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"values\"       \"rotation\"     \"n.obs\"        \"communality\"  \"loadings\"    \n",
       " [6] \"fit\"          \"fit.off\"      \"fn\"           \"Call\"         \"uniquenesses\"\n",
       "[11] \"complexity\"   \"chi\"          \"EPVAL\"        \"R2\"           \"objective\"   \n",
       "[16] \"residual\"     \"rms\"          \"factors\"      \"dof\"          \"null.dof\"    \n",
       "[21] \"null.model\"   \"criteria\"     \"STATISTIC\"    \"PVAL\"         \"weights\"     \n",
       "[26] \"r.scores\"     \"rot.mat\"      \"Vaccounted\"   \"Structure\"    \"scores\"      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Loadings:\n",
       "  RC3    RC2    RC1   \n",
       "x  0.570  0.465  0.676\n",
       "y  0.561  0.451  0.694\n",
       "z  0.853  0.330  0.405\n",
       "r -0.305 -0.896 -0.323\n",
       "\n",
       "                 RC3   RC2   RC1\n",
       "SS loadings    1.460 1.331 1.206\n",
       "Proportion Var 0.365 0.333 0.302\n",
       "Cumulative Var 0.365 0.698 0.999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.57\n",
      "[1] 1.131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>RC3</th><th scope=col>RC2</th><th scope=col>RC1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.6424297 </td><td>-2.68904962</td><td> 0.17239034</td></tr>\n",
       "\t<tr><td> 0.6343329 </td><td>-0.33903210</td><td>-1.97465570</td></tr>\n",
       "\t<tr><td>-1.1897324 </td><td> 0.39758963</td><td>-0.43651149</td></tr>\n",
       "\t<tr><td>-0.7514567 </td><td> 0.64099269</td><td>-0.58777416</td></tr>\n",
       "\t<tr><td>-0.8482129 </td><td> 0.64312056</td><td> 0.05161648</td></tr>\n",
       "\t<tr><td> 0.7861687 </td><td> 0.52358257</td><td>-0.78499105</td></tr>\n",
       "\t<tr><td>-0.1820796 </td><td> 0.52454619</td><td> 0.40078627</td></tr>\n",
       "\t<tr><td>-0.5213260 </td><td> 0.31641025</td><td> 1.48703555</td></tr>\n",
       "\t<tr><td> 0.6950234 </td><td> 0.09567771</td><td> 1.10646882</td></tr>\n",
       "\t<tr><td> 2.0197123 </td><td>-0.11383789</td><td> 0.56563493</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lll}\n",
       " RC3 & RC2 & RC1\\\\\n",
       "\\hline\n",
       "\t -0.6424297  & -2.68904962 &  0.17239034\\\\\n",
       "\t  0.6343329  & -0.33903210 & -1.97465570\\\\\n",
       "\t -1.1897324  &  0.39758963 & -0.43651149\\\\\n",
       "\t -0.7514567  &  0.64099269 & -0.58777416\\\\\n",
       "\t -0.8482129  &  0.64312056 &  0.05161648\\\\\n",
       "\t  0.7861687  &  0.52358257 & -0.78499105\\\\\n",
       "\t -0.1820796  &  0.52454619 &  0.40078627\\\\\n",
       "\t -0.5213260  &  0.31641025 &  1.48703555\\\\\n",
       "\t  0.6950234  &  0.09567771 &  1.10646882\\\\\n",
       "\t  2.0197123  & -0.11383789 &  0.56563493\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "RC3 | RC2 | RC1 | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| -0.6424297  | -2.68904962 |  0.17239034 | \n",
       "|  0.6343329  | -0.33903210 | -1.97465570 | \n",
       "| -1.1897324  |  0.39758963 | -0.43651149 | \n",
       "| -0.7514567  |  0.64099269 | -0.58777416 | \n",
       "| -0.8482129  |  0.64312056 |  0.05161648 | \n",
       "|  0.7861687  |  0.52358257 | -0.78499105 | \n",
       "| -0.1820796  |  0.52454619 |  0.40078627 | \n",
       "| -0.5213260  |  0.31641025 |  1.48703555 | \n",
       "|  0.6950234  |  0.09567771 |  1.10646882 | \n",
       "|  2.0197123  | -0.11383789 |  0.56563493 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      RC3        RC2         RC1        \n",
       " [1,] -0.6424297 -2.68904962  0.17239034\n",
       " [2,]  0.6343329 -0.33903210 -1.97465570\n",
       " [3,] -1.1897324  0.39758963 -0.43651149\n",
       " [4,] -0.7514567  0.64099269 -0.58777416\n",
       " [5,] -0.8482129  0.64312056  0.05161648\n",
       " [6,]  0.7861687  0.52358257 -0.78499105\n",
       " [7,] -0.1820796  0.52454619  0.40078627\n",
       " [8,] -0.5213260  0.31641025  1.48703555\n",
       " [9,]  0.6950234  0.09567771  1.10646882\n",
       "[10,]  2.0197123 -0.11383789  0.56563493"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prv<-principal(data, nfactors=3, rotate=\"varimax\")\n",
    "# PCA 함수에서 사용가능한 변수 및 함수 \n",
    "names(prv)\n",
    "# 각차원의 주성분 영향도 확인 \n",
    "prv$loadings\n",
    "# 그럼 새로운 데이터에 대한 차원 score 를 구해보자 \n",
    "test_x = 1\n",
    "test_y = 2\n",
    "test_z = 3\n",
    "# RC3 차원 주성분 하나 사용\n",
    "print(0.570 * test_x)\n",
    "# RC3 차원 주성분 두개 사용 \n",
    "print(0.570 * test_x + 0.561 * test_x)\n",
    "#biplot(prv)\n",
    "# 그냥 훈련 데이터 전체 Scores \n",
    "prv$scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
